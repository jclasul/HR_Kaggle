{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from math import exp as exp\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make Importable module\n",
    "class IDnumbers(object):\n",
    "    def GetFile(self, Mode, WriteString = None, FileName = 'IDnumbers'):\n",
    "        '''\n",
    "        self: IDnumbers\n",
    "        Mode: (a) for writing; (r) for reading\n",
    "        WriteString: !!! IN STRING FORMAT !!! otherwise TypeError exception gets executed;\n",
    "                     not required for reading\n",
    "                           \n",
    "        FileName: default = IDnumbers; change to create new file\n",
    "        '''\n",
    "        try:\n",
    "            with open(FileName, mode=Mode) as f:\n",
    "                if Mode == 'a':\n",
    "                    f.write(str(WriteString) + \"\\n\")\n",
    "                else:\n",
    "                    self.IDnumbers_read = f.read()\n",
    "                    return self.IDnumbers_read.split()\n",
    "            f.closed       \n",
    "        except FileNotFoundError:\n",
    "            print('NOT FOUND -- wrote to disk: ', FileName)\n",
    "            open(FileName, mode = 'w')\n",
    "            self.GetFile(Mode='a', FileName=FileName, WriteString = WriteString)\n",
    "        except TypeError:\n",
    "            print('ERROR \\n')\n",
    "            print('Please provide input value to write')\n",
    "    def EraseFile(self, FileName = 'IDnumbers'):\n",
    "        '''\n",
    "        Erase content from FILE; change FileName if needed\n",
    "        '''\n",
    "        open(FileName, mode='w').close()\n",
    "        \n",
    "WriteIO = IDnumbers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set-up Plotly\n",
    "tls.set_credentials_file(username=\"jclasul\", api_key=\"MKXHNoKq9cRqNshsRQlh\")\n",
    "tls.set_config_file(sharing=\"public\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1470, 32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HR = pd.read_csv(\"HRIN.csv\")\n",
    "\n",
    "# Drop useless variables\n",
    "# find way to automate without looking at plots\n",
    "HR.drop([\"EmployeeCount\",\"Over18\",\"StandardHours\"], axis = 1, inplace=True)\n",
    "\n",
    "# 35 variables for 1470 persons before drops\n",
    "HR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64     24\n",
       "object     8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all variables and data types\n",
    "HR.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dealing with CATEGORICAL variables\n",
    "# # # # # # # # # # # #\n",
    "# Method 1:\n",
    "# One-Hot encoding\n",
    "# # # # # # # # # # # #\n",
    "\n",
    "recast = pd.get_dummies(HR, sparse=True, drop_first=True)\n",
    "recast_corr = pd.DataFrame.dropna(recast.corr(), axis=[0,1],how=\"all\")\n",
    "\n",
    "# # # # # # # # # # # #\n",
    "# Method 2:\n",
    "# Label Encoding\n",
    "# # # # # # # # # # # #\n",
    "#\n",
    "# Convert all Object dtypes to Categorical\n",
    "\n",
    "def TO_CAT(col):\n",
    "    if col.dtype == \"object\":\n",
    "        return col.astype(\"category\").cat.codes\n",
    "    else:\n",
    "        return col\n",
    "    \n",
    "encoding = HR.apply(TO_CAT, axis=0)\n",
    "encoding_corr = pd.DataFrame.dropna(encoding.corr(), axis=[0,1],how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotly CONTOUR map\n",
    "# \n",
    "# values have to be in LIST for PLOTLY, convert tolist and use COLUMN names for axis\n",
    "# \n",
    "\n",
    "py.iplot([go.Contour(z=recast_corr.values.tolist(),\n",
    "                   x=recast_corr.columns.tolist(),\n",
    "                   y=recast_corr.columns.tolist())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotly CONTOUR map\n",
    "# \n",
    "# values have to be in LIST for PLOTLY, convert tolist and use COLUMN names for axis\n",
    "# \n",
    "\n",
    "py.iplot([go.Contour(z=encoding_corr.values.tolist(),\n",
    "                   x=encoding_corr.columns.tolist(),\n",
    "                   y=encoding_corr.columns.tolist())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting Function\n",
    "# Using Encoded labels\n",
    "#\n",
    "# To Add: Category names !!\n",
    "#\n",
    "def GET_CAT(COLUMN):\n",
    "    CCDict = {}\n",
    "    if HR[COLUMN].dtype == 'O': \n",
    "        CCats = HR[COLUMN].astype(\"category\").cat.categories.tolist()\n",
    "        for i,CCat in enumerate(CCats):\n",
    "            CCDictUpdate = {CCat: i}\n",
    "            CCDict.update(CCDictUpdate)\n",
    "        return CCDict\n",
    "            \n",
    "\n",
    "def MakeGraph(DATA,INPUT,RESPONSE=\"Attrition\"):\n",
    "    for VARIABLE in INPUT:\n",
    "        if VARIABLE == RESPONSE:\n",
    "            continue\n",
    "            \n",
    "        sns.set_style(\"whitegrid\")\n",
    "        sns.set_palette(\"muted\")\n",
    "        plt.figure(figsize=(12,5))\n",
    "        plt.suptitle(\"{:s} and {:s} graphs\".format(VARIABLE,RESPONSE), fontsize=\"x-large\")\n",
    "\n",
    "        p1 = plt.subplot(2,2,2)\n",
    "        sns.boxplot(y=DATA[RESPONSE], x=DATA[VARIABLE], orient=\"h\")\n",
    "        plt.legend()\n",
    "\n",
    "        p2 = plt.subplot(2,2,4, sharex=p1)\n",
    "        if RESPONSE == \"Attrition\":\n",
    "            sns.distplot(DATA.loc[DATA[RESPONSE] == 0][VARIABLE], label=\"Stayed\")\n",
    "            sns.distplot(DATA.loc[DATA[RESPONSE] == 1][VARIABLE], label=\"Left\")               \n",
    "        plt.ylabel(\"Probability Density\")\n",
    "        plt.legend()\n",
    "\n",
    "        p3 = plt.subplot(1,2,1)\n",
    "        sns.pointplot(x=DATA[RESPONSE],y=DATA[VARIABLE], capsize = 0.2)\n",
    "        plt.show()\n",
    "        print(GET_CAT(VARIABLE))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA = encoding\n",
    "INPUT = pd.DataFrame.select_dtypes(DATA, exclude=[\"object\"]).columns\n",
    "RESPONSE = \"Attrition\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# CREATE graphs\n",
    "#\n",
    "\n",
    "#MakeGraph(DATA,INPUT,RESPONSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# START machine learning\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# something\n",
    "# something else\n",
    "# finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions::\n",
    "#\n",
    "def SPLIT_DATA(DATA=encoding, RAND=True, Testsize=0.3):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(DATA.drop(\"Attrition\",axis=1), \n",
    "                                                        DATA[\"Attrition\"], test_size = Testsize)\n",
    "    \n",
    "    if RAND == True:\n",
    "        list_of_random_items = GET_RANDOM(DATA=x_train)\n",
    "        #x_train.drop(list_of_random_items, axis = 1, inplace= True)\n",
    "\n",
    "        [DataSet.drop(list_of_random_items, axis = 1, inplace = True) for DataSet in [x_train,x_test]]\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "# RANDOM variable selection\n",
    "def GET_RANDOM(DATA):\n",
    "    group_of_items = set(DATA.columns)\n",
    "    num_to_select = np.random.randint(1,len(group_of_items))\n",
    "    list_of_random_items = random.sample(group_of_items, num_to_select)\n",
    "    \n",
    "    return list_of_random_items\n",
    "\n",
    "# TO:DO\n",
    "# IMPROVE only MODEL initiation changes, reduce code\n",
    "#\n",
    "\n",
    "def TRAIN_MODEL_LOG(RAND=True, Testsize=0.3):\n",
    "    # SPLIT Data, using CALL SPLIT_DATA function\n",
    "    # To include ALL variables select RAND = False\n",
    "    # Testsize default = 0.3\n",
    "    x_train, x_test, y_train, y_test = SPLIT_DATA(RAND=RAND, Testsize=Testsize)\n",
    "    \n",
    "    # USE LogisticRegression from SKLEARN\n",
    "    model = LogisticRegression()    \n",
    "    # FIT the model with training input\n",
    "    model.fit(x_train,y_train)  \n",
    "    \n",
    "    # PREDICT using LRM with test data set\n",
    "    PREDICTIONS = model.predict(x_test)\n",
    "    \n",
    "    # evaluate predictions \n",
    "    accuracy = accuracy_score(y_test,PREDICTIONS)\n",
    "    # CALL ConfMatrix function\n",
    "    ConfMatrix, INCORRECT_T1, INCORRECT_T2 = CONF_MATRIX(y_test, PREDICTIONS)\n",
    "    \n",
    "    OUTLIST = [accuracy, INCORRECT_T1, INCORRECT_T2, len(x_train.columns), x_train.columns.tolist(), ConfMatrix.flatten()]    \n",
    "    return OUTLIST   \n",
    "\n",
    "def TRAIN_MODEL_XGBoost_1(RAND=True, Testsize=0.3):\n",
    "    # SPLIT Data, using CALL SPLIT_DATA function\n",
    "    # To include ALL variables select RAND = False\n",
    "    # Testsize default = 0.3\n",
    "    x_train, x_test, y_train, y_test = SPLIT_DATA(RAND=RAND, Testsize=Testsize)\n",
    "    \n",
    "    # USE XGBClassifier from XGBoost\n",
    "    model = XGBClassifier()\n",
    "    # FIT the model with training input\n",
    "    model.fit(x_train,y_train)\n",
    "\n",
    "    # make predictions for test data\n",
    "    PREDICTIONS = model.predict(x_test)\n",
    "    # PREDICTIONS = [round(value) for value in y_pred]\n",
    "\n",
    "    # evaluate predictions\n",
    "    accuracy = accuracy_score(y_test, PREDICTIONS)\n",
    "    # CALL ConfMatrix function\n",
    "    ConfMatrix, INCORRECT_T1, INCORRECT_T2 = CONF_MATRIX(y_test, PREDICTIONS)\n",
    "    \n",
    "    OUTLIST = [accuracy, INCORRECT_T1, INCORRECT_T2, len(x_train.columns), x_train.columns.tolist(), ConfMatrix.flatten()]    \n",
    "    return OUTLIST   \n",
    "\n",
    "## END TO:DO\n",
    "\n",
    "def CONF_MATRIX(y_test, PREDICTIONS):\n",
    "    # CREATE confusion matrix and get TI TII errors\n",
    "    ConfMatrix = confusion_matrix(y_test, PREDICTIONS)\n",
    "    # CALL TI TII function\n",
    "    INCORRECT_T1,INCORRECT_T2 = TITII(DATA = ConfMatrix)\n",
    "    \n",
    "    return ConfMatrix, INCORRECT_T1, INCORRECT_T2\n",
    "\n",
    "def TITII(DATA):\n",
    "    CORRECT_TRUE = DATA[-1,-1]/DATA[-1,:].sum()\n",
    "    INCORRECT_T2 = 1-CORRECT_TRUE\n",
    "    CORRECT_FALSE = DATA[0,0]/DATA[0,:].sum()\n",
    "    INCORRECT_T1 = 1-CORRECT_FALSE\n",
    "    \n",
    "    return INCORRECT_T1,INCORRECT_T2  \n",
    "\n",
    "def MAKE_HM(MODEL_NAME, ConfMatrix = None, y_test = None, PREDICTIONS = None, Score=\"Not Given\"):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    if ConfMatrix is None:\n",
    "        ConfMatrix, INCORRECT_T1, INCORRECT_T2 = CONF_MATRIX(y_test,PREDICTIONS)\n",
    "    else:\n",
    "        ConfMatrix = ConfMatrix.reshape(2,2)\n",
    "        INCORRECT_T1,INCORRECT_T2 = TITII(ConfMatrix)\n",
    "    \n",
    "    sns.heatmap(ConfMatrix, annot=True, fmt=\".3f\", linewidths=1, square=True, cmap=\"icefire\", cbar=False) \n",
    "    \n",
    "    # LABELS & TITLES\n",
    "    plt.ylabel(\"Actual label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.suptitle(\"The Score for the {} is : {}, Type II : {}\".format(MODEL_NAME,Score,INCORRECT_T2))\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "250\n",
      "500\n",
      "750\n",
      "1000\n",
      "1250\n",
      "1500\n",
      "1750\n",
      "2000\n",
      "2250\n",
      "2500\n",
      "2750\n",
      "3000\n",
      "3250\n",
      "3500\n",
      "3750\n",
      "4000\n",
      "4250\n",
      "4500\n",
      "4750\n",
      "5000\n",
      "5250\n",
      "5500\n",
      "5750\n",
      "6000\n",
      "6250\n",
      "6500\n",
      "6750\n",
      "7000\n",
      "7250\n",
      "7500\n",
      "7750\n",
      "8000\n",
      "8250\n",
      "8500\n",
      "8750\n",
      "9000\n",
      "9250\n",
      "9500\n",
      "9750\n"
     ]
    }
   ],
   "source": [
    "ModelResults = []\n",
    "for i in range(0,10000):    \n",
    "#     ModelResults.append(TRAIN_MODEL_LOG())\n",
    "    if i % 250 == 0:\n",
    "        print(i)\n",
    "    \n",
    "    # Store on local drive in case of crashes\n",
    "    WriteIO.GetFile(Mode=\"a\", WriteString = TRAIN_MODEL_LOG(), FileName=\"IDnumbers_LRM_T1\")\n",
    "    WriteIO.GetFile(Mode=\"a\", WriteString = TRAIN_MODEL_XGBoost_1(), FileName=\"IDnumbers_XGB_T1\")\n",
    "    \n",
    "#ModelResults[4] = ModelResults[3].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"IDnumbers_XGBoost_1\"\n",
    "\n",
    "SCORES = []\n",
    "with open(MODEL_NAME) as f:\n",
    "    for line in f:\n",
    "        line_data = [line for line in line.split(\",\")]\n",
    "        SCORE = [float(scores.strip(\"[]\").strip(\"'\")) for scores in line_data[0:4]]\n",
    "        SCORES.append(SCORE)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SCORES = pd.DataFrame(SCORES)\n",
    "SCORES.rename(columns={0:\"Score\", 1:\"Error1\",2:\"Error2\",3:\"NVars\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRAPH\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "SCORES.groupby(\"NVars\")[[\"Score\",\"Error2\"]].median().plot()\n",
    "plt.suptitle(\"Median Score and Error2 for {}\".format(MODEL_NAME))\n",
    "plt.show()\n",
    "\n",
    "print(\"Total runs : {}\".format(len(SCORES.Score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL 30 variables:\n",
    "# Logistic Regression\n",
    "LRM = TRAIN_MODEL_LOG(RAND=False)\n",
    "MAKE_HM(\"Logistic Regression\",ConfMatrix=LRM[5], Score=LRM[0])\n",
    "print(\"Total Variables : {}\".format(LRM[3]))\n",
    "\n",
    "# XGBoost classifier\n",
    "XGBoost_1 = TRAIN_MODEL_XGBoost_1(RAND=False)\n",
    "MAKE_HM(\"XGBoost\", XGBoost_1[5], Score=XGBoost_1[0])\n",
    "print(\"Total Variables : {}\".format(XGBoost_1[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
